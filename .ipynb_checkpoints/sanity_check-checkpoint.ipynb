{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import os\n",
    "from pipeline import utils\n",
    "from model import drivenet\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/daniel/Dropbox/udacity_challenge2'"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_dict = {\n",
    "\n",
    "    'driveNet': drivenet.DriveNet\n",
    "\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'MODEL_TITLE': 'driveNet', 'CHANNEL': 3, 'HEIGHT': 66, 'BATCH_SIZE': 100, 'NUM_ITER': 100000, 'WIDTH': 200, 'MODEL_FILE': 'drivenet'}\n"
     ]
    }
   ],
   "source": [
    "models = utils.from_recipe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--config--\n",
      "model: driveNet\n",
      "height: 66\n",
      "width: 200\n",
      "channel: 3\n",
      "num_iter: 100000\n",
      "--config--\n",
      "drivenet.py\n",
      "save/log/driveNet\n",
      "here\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <bound method BaseSession.__del__ of <tensorflow.python.client.session.InteractiveSession object at 0x12b538048>>\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/daniel/anaconda3/envs/tensorflow/lib/python3.5/site-packages/tensorflow/python/client/session.py\", line 522, in __del__\n",
      "    self.close()\n",
      "  File \"/Users/daniel/anaconda3/envs/tensorflow/lib/python3.5/site-packages/tensorflow/python/client/session.py\", line 1262, in close\n",
      "    self._default_session.__exit__(None, None, None)\n",
      "  File \"/Users/daniel/anaconda3/envs/tensorflow/lib/python3.5/contextlib.py\", line 66, in __exit__\n",
      "    next(self.gen)\n",
      "  File \"/Users/daniel/anaconda3/envs/tensorflow/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\", line 3536, in get_controller\n",
      "    % type(default))\n",
      "AssertionError: Nesting violated for default stack of <class 'weakref'> objects\n"
     ]
    }
   ],
   "source": [
    "for model in models:\n",
    "    print(\"--config--\")\n",
    "    print(\"model: %s\" %  model['MODEL_TITLE'])\n",
    "    print(\"height: %d\" % model['HEIGHT'])\n",
    "    print(\"width: %d\" % model['WIDTH'])\n",
    "    print(\"channel: %d\" % model['CHANNEL'])\n",
    "    print(\"num_iter: %d\" % model['NUM_ITER'])\n",
    "    print(\"--config--\")\n",
    "    if model['MODEL_TITLE'] == 'driveNet':\n",
    "        print('drivenet.py')\n",
    "        MODEL_TITLE = model[\"MODEL_TITLE\"]\n",
    "        SUMMARY_DIR = 'save/log/' + MODEL_TITLE\n",
    "        \n",
    "        if not os.path.exists(SUMMARY_DIR):\n",
    "            print(SUMMARY_DIR)\n",
    "            print('here')\n",
    "            os.makedirs(SUMMARY_DIR)\n",
    "        # get session\n",
    "        sess = tf.InteractiveSession()\n",
    "\n",
    "\n",
    "        dnn = model_dict[model['MODEL_TITLE']](width=model[\"WIDTH\"], height=model[\"HEIGHT\"], channel=model[\"CHANNEL\"])\n",
    "        dnn.inference()\n",
    "        with tf.name_scope('loss'):\n",
    "            loss = tf.reduce_mean(tf.square(tf.sub(dnn.y_, dnn.y)))\n",
    "            tf.scalar_summary('mse', loss)\n",
    "        train_step = tf.train.AdamOptimizer(1e-4).minimize(loss)\n",
    "        sess.run(tf.initialize_all_variables())\n",
    "        merged = tf.merge_all_summaries()\n",
    "        train_writer = tf.train.SummaryWriter(SUMMARY_DIR + '/train', sess.graph)\n",
    "        test_writer = tf.train.SummaryWriter(SUMMARY_DIR + '/test')\n",
    "        \n",
    "                # saver\n",
    "        saver = tf.train.Saver()\n",
    "\n",
    "        for i in range(NUM_ITER):\n",
    "            xs, ys = driving_data.LoadTrainBatch(BATCH_SIZE)\n",
    "            if i % 10 == 0:\n",
    "                xs, ys = driving_data.LoadValBatch(BATCH_SIZE)\n",
    "                summary, mse = sess.run([merged, loss], feed_dict={dnn.x: xs, dnn.y_: ys, dnn.keep_prob: 0.8})\n",
    "                test_writer.add_summary(summary, i)\n",
    "            elif i % 100 == 99:  # Record execution stats\n",
    "                run_options = tf.RunOptions(trace_level=tf.RunOptions.FULL_TRACE)\n",
    "                run_metadata = tf.RunMetadata()\n",
    "                summary, _ = sess.run([merged, train_step],\n",
    "                                      feed_dict={dnn.x: xs, dnn.y_: ys, dnn.keep_prob: 0.8},\n",
    "                                      options=run_options,\n",
    "                                      run_metadata=run_metadata)\n",
    "                train_writer.add_run_metadata(run_metadata, 'step%03d' % i)\n",
    "                train_writer.add_summary(summary, i)\n",
    "                print('Adding run metadata for', i)\n",
    "            else:\n",
    "                summary, _ = sess.run([merged, train_step], feed_dict={dnn.x: xs, dnn.y_: ys, dnn.keep_prob: 0.8})\n",
    "                train_writer.add_summary(summary, i)\n",
    "\n",
    "            if i % 100 == 0:\n",
    "                if not os.path.exists(LOGDIR):\n",
    "                    os.makedirs(LOGDIR)\n",
    "                #\n",
    "                checkpoint_path = os.path.join(LOGDIR, MODEL_TITLE + \".ckpt\")\n",
    "                filename = saver.save(sess, checkpoint_path)\n",
    "                print(\"Model saved in file: %s\" % filename)\n",
    "\n",
    "                json_data = {\"iter\": i, \"mse\": mse}\n",
    "                utils.append(MODEL_TITLE, json_data)\n",
    "\n",
    "        train_writer.close()\n",
    "        test_writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:tensorflow]",
   "language": "python",
   "name": "conda-env-tensorflow-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
