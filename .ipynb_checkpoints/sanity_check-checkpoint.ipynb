{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import os\n",
    "from pipeline import utils\n",
    "from model import drivenet\n",
    "import tensorflow as tf\n",
    "from model.driving_data import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/daniel/Dropbox/udacity_challenge2'"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model_dict = {\n",
    "\n",
    "    'driveNet': drivenet.DriveNet\n",
    "\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'MODEL_TITLE': 'driveNet', 'CHANNEL': 3, 'HEIGHT': 66, 'BATCH_SIZE': 100, 'NUM_ITER': 100000, 'WIDTH': 200, 'MODEL_FILE': 'drivenet'}\n"
     ]
    }
   ],
   "source": [
    "model_configs = utils.from_recipe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <bound method BaseSession.__del__ of <tensorflow.python.client.session.InteractiveSession object at 0x144246c88>>\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/daniel/anaconda3/envs/tensorflow/lib/python3.5/site-packages/tensorflow/python/client/session.py\", line 522, in __del__\n",
      "    self.close()\n",
      "  File \"/Users/daniel/anaconda3/envs/tensorflow/lib/python3.5/site-packages/tensorflow/python/client/session.py\", line 1262, in close\n",
      "    self._default_session.__exit__(None, None, None)\n",
      "  File \"/Users/daniel/anaconda3/envs/tensorflow/lib/python3.5/contextlib.py\", line 66, in __exit__\n",
      "    next(self.gen)\n",
      "  File \"/Users/daniel/anaconda3/envs/tensorflow/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\", line 3536, in get_controller\n",
      "    % type(default))\n",
      "AssertionError: Nesting violated for default stack of <class 'weakref'> objects\n"
     ]
    }
   ],
   "source": [
    "for config in model_configs:\n",
    "\n",
    "    # config\n",
    "    NUM_ITER = config[\"NUM_ITER\"]\n",
    "    BATCH_SIZE = config[\"BATCH_SIZE\"]\n",
    "    MODEL_TITLE = config[\"MODEL_TITLE\"]\n",
    "    MODEL_FILE = config[\"MODEL_FILE\"]\n",
    "    SUMMARY_DIR = 'save/log/' + MODEL_TITLE\n",
    "    WIDTH = config[\"WIDTH\"]\n",
    "    HEIGHT = config[\"HEIGHT\"]\n",
    "    CHANNEL = config[\"CHANNEL\"]\n",
    "\n",
    "    if not os.path.exists(SUMMARY_DIR):\n",
    "        os.makedirs(SUMMARY_DIR)\n",
    "    # get session\n",
    "    sess = tf.InteractiveSession()\n",
    "\n",
    "    # setupt dataset\n",
    "    driving_data = Dataset(DATA_DIR='rawdata/driving_dataset', file_name='data.txt', width=WIDTH, height=HEIGHT)\n",
    "\n",
    "    # setup model\n",
    "    dnn = model_dict[MODEL_TITLE](width=WIDTH, height=HEIGHT, channel=CHANNEL)\n",
    "    dnn.inference()\n",
    "\n",
    "    with tf.name_scope('loss'):\n",
    "        loss = tf.reduce_mean(tf.square(tf.sub(dnn.y_, dnn.y)))\n",
    "        tf.scalar_summary('mse', loss)\n",
    "\n",
    "    # set up optimizer\n",
    "    train_step = tf.train.AdamOptimizer(1e-4).minimize(loss)\n",
    "    sess.run(tf.initialize_all_variables())\n",
    "\n",
    "    # summary statistics\n",
    "    merged = tf.merge_all_summaries()\n",
    "    train_writer = tf.train.SummaryWriter(SUMMARY_DIR + '/train', sess.graph)\n",
    "    test_writer = tf.train.SummaryWriter(SUMMARY_DIR + '/test')\n",
    "\n",
    "    # saver\n",
    "    saver = tf.train.Saver()\n",
    "\n",
    "#     for i in range(NUM_ITER):\n",
    "#         xs, ys = driving_data.LoadTrainBatch(BATCH_SIZE)\n",
    "#         if i % 10 == 0:\n",
    "#             xs, ys = driving_data.LoadValBatch(BATCH_SIZE)\n",
    "#             summary, mse = sess.run([merged, loss], feed_dict={dnn.x: xs, dnn.y_: ys, dnn.keep_prob: 0.8})\n",
    "#             test_writer.add_summary(summary, i)\n",
    "#         elif i % 100 == 99:  # Record execution stats\n",
    "#             run_options = tf.RunOptions(trace_level=tf.RunOptions.FULL_TRACE)\n",
    "#             run_metadata = tf.RunMetadata()\n",
    "#             summary, _ = sess.run([merged, train_step],\n",
    "#                                   feed_dict={dnn.x: xs, dnn.y_: ys, dnn.keep_prob: 0.8},\n",
    "#                                   options=run_options,\n",
    "#                                   run_metadata=run_metadata)\n",
    "#             train_writer.add_run_metadata(run_metadata, 'step%03d' % i)\n",
    "#             train_writer.add_summary(summary, i)\n",
    "#             print('Adding run metadata for', i)\n",
    "#         else:\n",
    "#             summary, _ = sess.run([merged, train_step], feed_dict={dnn.x: xs, dnn.y_: ys, dnn.keep_prob: 0.8})\n",
    "#             train_writer.add_summary(summary, i)\n",
    "\n",
    "#         if i % 100 == 0:\n",
    "#             if not os.path.exists(LOGDIR):\n",
    "#                 os.makedirs(LOGDIR)\n",
    "#             #\n",
    "#             checkpoint_path = os.path.join(LOGDIR, MODEL_TITLE + \".ckpt\")\n",
    "#             filename = saver.save(sess, checkpoint_path)\n",
    "#             print(\"Model saved in file: %s\" % filename)\n",
    "\n",
    "#             json_data = {\"iter\": i, \"mse\": mse}\n",
    "#             utils.append(MODEL_TITLE, json_data)\n",
    "\n",
    "#     train_writer.close()\n",
    "#     test_writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:tensorflow]",
   "language": "python",
   "name": "conda-env-tensorflow-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
